{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f738ff-d430-4e96-bcc0-caede6f5594b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade llama-index        # core\n",
    "%pip install --upgrade llama-index-llms-google-genai  # Google / Gemini LLM integration\n",
    "%pip install --upgrade llama-index-embeddings-google-genai  # embeddings via Google GenAI\n",
    "%pip install --upgrade google-generativeai  # underlying Google SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a4010c-6689-42b9-9e18-6d1f53f21b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pinecone import Pinecone\n",
    "from llama_index.core import (\n",
    " Settings,\n",
    " VectorStoreIndex,\n",
    " SimpleDirectoryReader,\n",
    " KeywordTableIndex,)\n",
    "from llama_index.vector_stores.pinecone import PineconeVectorStore\n",
    "from llama_index.llms.google_genai import GoogleGenAI\n",
    "from llama_index.embeddings.google_genai import GoogleGenAIEmbedding\n",
    "from llama_index.core.tools import QueryEngineTool, ToolMetadata\n",
    "from llama_index.core.selectors import LLMSingleSelector\n",
    "from llama_index.core.query_engine import RouterQueryEngine,SubQuestionQueryEngine\n",
    "from llama_index.core.question_gen import LLMQuestionGenerator\n",
    "from llama_index.core.query_engine import SubQuestionQueryEngine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ee441b-884c-4a6e-a207-fdeafb2f65f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================ 1) EMBEDDING / LLM LAYER ============================\n",
    "# ============================ 2) DATA / INDEX LAYER ============================\n",
    "# Keep LLM OFF while loading PDFs (prevents accidental calls)\n",
    "# Set embedding BEFORE building Pinecone index\n",
    "Settings.embed_model = GoogleGenAIEmbedding(\n",
    "    model_name=\"models/text-embedding-004\",\n",
    "    api_key=\"\"   # or your key directly\n",
    ")\n",
    "\n",
    "Settings.llm = None\n",
    "try:\n",
    " docs = SimpleDirectoryReader(\"./GenAI/GenAI-NoteBooks/coffee_pages\",required_exts=[\".html\"]).load_data()\n",
    "except TypeError:\n",
    " docs = SimpleDirectoryReader(\"./GenAI/GenAI-NoteBooks/coffee_pages\",file_exts=[\".html\"]).load_data()\n",
    "\n",
    "kw_idx = KeywordTableIndex.from_documents(docs)\n",
    "\n",
    "# Pinecone semantic index\n",
    "pc = Pinecone(api_key=\"pcsk_3v68tN_L3G7scFvZJ8FtqsGh4T3yfHS86sXPfnojrAFUfx5D6XnDvHcWrYKy5T4CcRSZXs\")\n",
    "pc_index = pc.Index(\"coffeeindex\")\n",
    "vstore = PineconeVectorStore(pinecone_index=pc_index,text_key=\"text\") # change if you used \"page_content\"\n",
    "sem_idx = VectorStoreIndex.from_vector_store(vstore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196fb2cf-a50b-4cc3-b29b-8bde11ddfeb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn LLM ON now\n",
    "Settings.llm = GoogleGenAI(\n",
    " model=\"gemini-2.5-flash\",\n",
    " api_key=\"\",\n",
    " temperature=0.2,\n",
    " max_tokens=2024,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55dc1232-606d-4458-ad50-d4c562cf6b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrap each index as a query engine (single-shot synthesis via response_mode=\"compact\")\n",
    "qe_sem = sem_idx.as_query_engine(similarity_top_k=5,response_mode=\"compact\", llm=Settings.llm)\n",
    "qe_kw = kw_idx.as_query_engine(response_mode=\"compact\",llm=Settings.llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367a5fb7-36ec-49d4-9768-1d802b30999c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Package as proper tools (use ToolMetadata, not dict)\n",
    "tools = [\n",
    " QueryEngineTool(query_engine=qe_sem,metadata=ToolMetadata(name=\"semantic\", description=\"General coffee KB(Pinecone)\")),\n",
    " QueryEngineTool(query_engine=qe_kw,metadata=ToolMetadata(name=\"keyword\", description=\"PDF keyword/headings lookup\")),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d0cbff9-82b6-4ed8-a8e0-70a7c728330c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================ 3) QUERY LAYER============================\n",
    "# (A) RouterQueryEngine -- route whole query to the best engine\n",
    "router = RouterQueryEngine.from_defaults(\n",
    " query_engine_tools=tools,\n",
    " selector=LLMSingleSelector.from_defaults(llm=Settings.llm),\n",
    ")\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "print(router.query(\"Find entries mentioning ashwagandha in titles or headings.\")) # likely routes to keyword\n",
    "print(router.query(\"What is turmeric coffee?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81254ff5-a195-4a35-a0c5-8eb482c5c615",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install llama-index-question-gen-llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca0398d-d2a0-40b1-aa62-836892b02c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (B) SubQuestionQueryEngine -- split, route parts, then merge\n",
    "question_gen = LLMQuestionGenerator.from_defaults(llm=Settings.llm)\n",
    "subq = SubQuestionQueryEngine.from_defaults(\n",
    " query_engine_tools=tools,\n",
    " question_gen=question_gen,\n",
    " llm=Settings.llm,\n",
    ")\n",
    "print(subq.query(\"Compare turmeric coffee vs saffron coffee and give a one-paragraph verdict.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4861c4a-4fc7-426c-bf96-774527f9a6d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
