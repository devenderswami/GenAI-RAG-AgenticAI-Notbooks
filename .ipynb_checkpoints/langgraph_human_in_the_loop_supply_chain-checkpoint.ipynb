{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c7c9c70a-e7be-4a1a-aeee-94bc3ce68c94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langgraph in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (1.0.4)\n",
      "Collecting faiss-cpu\n",
      "  Downloading faiss_cpu-1.13.2-cp310-abi3-macosx_14_0_arm64.whl.metadata (7.6 kB)\n",
      "Requirement already satisfied: langchain in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (1.2.0)\n",
      "Requirement already satisfied: langchain-core in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (1.2.7)\n",
      "Requirement already satisfied: langchain-google-genai in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (4.2.0)\n",
      "Requirement already satisfied: langchain-community in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (0.4.1)\n",
      "Requirement already satisfied: python-dotenv in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (1.1.1)\n",
      "Requirement already satisfied: langgraph-checkpoint<4.0.0,>=2.1.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from langgraph) (3.0.1)\n",
      "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.2 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from langgraph) (1.0.5)\n",
      "Requirement already satisfied: langgraph-sdk<0.3.0,>=0.2.2 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from langgraph) (0.2.10)\n",
      "Requirement already satisfied: pydantic>=2.7.4 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from langgraph) (2.11.9)\n",
      "Requirement already satisfied: xxhash>=3.5.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from langgraph) (3.6.0)\n",
      "Requirement already satisfied: ormsgpack>=1.12.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph) (1.12.0)\n",
      "Requirement already satisfied: httpx>=0.25.2 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.10.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph) (3.11.3)\n",
      "Requirement already satisfied: numpy<3.0,>=1.25.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from faiss-cpu) (2.4.1)\n",
      "Requirement already satisfied: packaging in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from faiss-cpu) (23.2)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from langchain-core) (1.33)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from langchain-core) (0.5.0)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from langchain-core) (6.0.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from langchain-core) (8.5.0)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from langchain-core) (4.15.0)\n",
      "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from langchain-core) (0.12.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core) (3.0.0)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (1.0.0)\n",
      "Requirement already satisfied: requests>=2.0.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (2.32.5)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (0.25.0)\n",
      "Requirement already satisfied: anyio in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (4.12.0)\n",
      "Requirement already satisfied: certifi in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (1.0.9)\n",
      "Requirement already satisfied: idna in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from pydantic>=2.7.4->langgraph) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from pydantic>=2.7.4->langgraph) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from pydantic>=2.7.4->langgraph) (0.4.1)\n",
      "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from langchain-google-genai) (1.2.0)\n",
      "Requirement already satisfied: google-genai<2.0.0,>=1.56.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from langchain-google-genai) (1.59.0)\n",
      "Requirement already satisfied: google-auth<3.0.0,>=2.47.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from google-auth[requests]<3.0.0,>=2.47.0->google-genai<2.0.0,>=1.56.0->langchain-google-genai) (2.47.0)\n",
      "Requirement already satisfied: websockets<15.1.0,>=13.0.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from google-genai<2.0.0,>=1.56.0->langchain-google-genai) (15.0.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from google-genai<2.0.0,>=1.56.0->langchain-google-genai) (1.9.0)\n",
      "Requirement already satisfied: sniffio in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from google-genai<2.0.0,>=1.56.0->langchain-google-genai) (1.3.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from google-auth<3.0.0,>=2.47.0->google-auth[requests]<3.0.0,>=2.47.0->google-genai<2.0.0,>=1.56.0->langchain-google-genai) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from google-auth<3.0.0,>=2.47.0->google-auth[requests]<3.0.0,>=2.47.0->google-genai<2.0.0,>=1.56.0->langchain-google-genai) (4.9.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core) (2.5.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from rsa<5,>=3.1.4->google-auth<3.0.0,>=2.47.0->google-auth[requests]<3.0.0,>=2.47.0->google-genai<2.0.0,>=1.56.0->langchain-google-genai) (0.6.1)\n",
      "Requirement already satisfied: langchain-classic<2.0.0,>=1.0.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from langchain-community) (1.0.0)\n",
      "Requirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from langchain-community) (2.0.43)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from langchain-community) (3.12.13)\n",
      "Requirement already satisfied: dataclasses-json<0.7.0,>=0.6.7 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from langchain-community) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from langchain-community) (2.12.0)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from langchain-community) (0.4.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.6.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.20.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: langchain-text-splitters<2.0.0,>=1.0.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from langchain-classic<2.0.0,>=1.0.0->langchain-community) (1.1.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community) (1.1.0)\n",
      "Downloading faiss_cpu-1.13.2-cp310-abi3-macosx_14_0_arm64.whl (3.5 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0m3.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: faiss-cpu\n",
      "Successfully installed faiss-cpu-1.13.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install langgraph faiss-cpu langchain langchain-core langchain-google-genai langchain-community python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "93509cd8-c78f-40a5-9068-148ef40476c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from typing import TypedDict, Annotated, Sequence\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.messages import BaseMessage, SystemMessage, HumanMessage\n",
    "from langchain_core.tools import tool\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "# 0. SETUP API\n",
    "# if \"GOOGLE_API_KEY\" not in os.environ:\n",
    "    # os.environ[\"GOOGLE_API_KEY\"] = \"___\"\n",
    "\n",
    "# 1. DATA SETUP\n",
    "# A. Secure ERP Data\n",
    "data = {\n",
    "    \"product_id\": [\"GPU-X100\", \"GPU-X100\", \"CPU-Z50\",\"GPU-X100\"],\n",
    "    \"location\": [\"Taiwan\", \"Germany\", \"California\",\"india\"],\n",
    "    \"stock\": [0, 50, 100,50], # GPU out of stock in Taiwan\n",
    "    \"supplier\": [\"TechGlobal\", \"EuroChips\", \"SiliconValley Inc\",\"Swami Inc\"]\n",
    "}\n",
    "df_inventory = pd.DataFrame(data)\n",
    "\n",
    "# B. Unstructured News Data (Risks)\n",
    "news_feed = [\n",
    "    \"URGENT: Super Typhoon 'Kuna' is hitting Taiwan. Ports closed.\",\n",
    "    \"Strike Update: Germany logistics are operating normally.\",\n",
    "    \"Wire Update:: Inida logistic is working normally\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "f9cf8a9a-845c-4105-8c7a-dc5051ee4233",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
    ")\n",
    "vector_store = FAISS.from_documents([Document(page_content=x) for x in news_feed], embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "1c1d815a-dbcb-4a47-bc7c-37e641674329",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. TOOLS (For the Agent)\n",
    "@tool\n",
    "def check_external_risks(location: str):\n",
    "    \"\"\"Searches news for risks in a specific location.\"\"\"\n",
    "    retriever = vector_store.as_retriever(search_kwargs={\"k\": 1})\n",
    "    docs = retriever.invoke(location)\n",
    "    return f\"RISK REPORT: {docs[0].page_content}\" if docs else \"No risks found.\"\n",
    "\n",
    "tools = [check_external_risks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "a640635c-97e9-401f-afdc-c18cc369c34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. STATE\n",
    "class SupplyChainState(TypedDict):\n",
    "    messages: Annotated[Sequence[BaseMessage], add_messages]\n",
    "    product_query: str\n",
    "    erp_context: str # Stores the hard data string\n",
    "    last_product: str\n",
    "    last_location: str\n",
    "    pending_decision: dict | None\n",
    "    awaiting_human: bool\n",
    "    alternatives: list\n",
    "    decision_log: list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "1e32cffa-017a-4d22-966f-f109715be4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. NODES\n",
    "\n",
    "# NODE A: ERP Guard (Deterministic - No AI)\n",
    "def erp_lookup_node(state: SupplyChainState):\n",
    "    print(\"\\n[Node: ERP Guard] querying database...\")\n",
    "\n",
    "    query = state[\"product_query\"]\n",
    "    matches = df_inventory[df_inventory['product_id'].str.contains(query, case=False)]\n",
    "\n",
    "    if matches.empty:\n",
    "        state[\"erp_context\"] = \"Product not found.\"\n",
    "        state[\"last_product\"] = \"\"\n",
    "        state[\"last_location\"] = \"\"\n",
    "        state[\"alternatives\"] = []\n",
    "        return state\n",
    "\n",
    "    # Identify primary (requested) location from user message\n",
    "    user_msg = state[\"messages\"][-1].content.lower()\n",
    "    primary_location = None\n",
    "    for loc in matches[\"location\"].unique():\n",
    "        if loc.lower() in user_msg:\n",
    "            primary_location = loc\n",
    "            break\n",
    "\n",
    "    if not primary_location:\n",
    "        primary_location = matches.iloc[0][\"location\"]\n",
    "\n",
    "    # Build ERP context\n",
    "    context = \"FOUND INVENTORY:\\n\"\n",
    "    for _, row in matches.iterrows():\n",
    "        context += f\"- Loc: {row['location']} | Stock: {row['stock']}\\n\"\n",
    "\n",
    "    # ✅ DATA-DRIVEN alternative selection (THIS IS THE KEY)\n",
    "    alternatives = (\n",
    "        matches[\n",
    "            (matches[\"stock\"] > 0) &\n",
    "            (matches[\"location\"] != primary_location)\n",
    "        ][\"location\"]\n",
    "        .unique()\n",
    "        .tolist()\n",
    "    )\n",
    "\n",
    "    state[\"erp_context\"] = context\n",
    "    state[\"last_product\"] = matches.iloc[0][\"product_id\"]\n",
    "    state[\"last_location\"] = primary_location\n",
    "    state[\"alternatives\"] = alternatives\n",
    "\n",
    "    return state\n",
    "\n",
    "# NODE B: Agent (Probabilistic - AI)\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\",api_key=\"replace-with-your-key\").bind_tools(tools)\n",
    "\n",
    "def agent_node(state: SupplyChainState):\n",
    "    erp_data = state[\"erp_context\"]\n",
    "\n",
    "    sys_msg = SystemMessage(\n",
    "        content=f\"\"\"\n",
    "        ERP DATA (AUTHORITATIVE):\n",
    "        {erp_data}\n",
    "        \n",
    "        TASK:\n",
    "        - Identify risks\n",
    "        - Identify alternative suppliers WITH STOCK\n",
    "        - Propose options\n",
    "        - Do NOT finalize decisions\n",
    "        - Ask a question Like do they want to go ahead with alternative option that provided and take input\n",
    "        \"\"\"\n",
    "    )\n",
    "\n",
    "    response = llm.invoke([sys_msg] + state[\"messages\"])\n",
    "    state[\"messages\"].append(response)\n",
    "\n",
    "    # Proposal trigger (DATA-DRIVEN)\n",
    "    if \"FOUND INVENTORY\" in erp_data and \"Stock: 0\" in erp_data:\n",
    "        # alternatives = []\n",
    "        for line in erp_data.splitlines():\n",
    "            if \"Stock:\" in line and \"0\" not in line:\n",
    "                loc = line.split(\"Loc:\")[1].split(\"|\")[0].strip()\n",
    "                alternatives.append(loc)\n",
    "\n",
    "            if state.get(\"alternatives\"):\n",
    "                state[\"pending_decision\"] = {\n",
    "                    \"type\": \"ALTERNATIVE_LOCATION_AVAILABLE\",\n",
    "                    \"product\": state[\"last_product\"],\n",
    "                    \"options\": state[\"alternatives\"]\n",
    "                }\n",
    "\n",
    "    return state\n",
    "\n",
    "    \n",
    "def approval_node(state: SupplyChainState):\n",
    "    \"\"\"\n",
    "    This node PAUSES the graph and signals that human approval is required.\n",
    "    \"\"\"\n",
    "    state[\"awaiting_human\"] = True\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f73d9a9-5b1d-4347-bab3-4296f10defb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- SCENARIO: Sourcing from Taiwan (Risky) ---\n",
      "\n",
      "[Node: ERP Guard] querying database...\n",
      "\n",
      "[Node: ERP Guard] querying database...\n",
      "\n",
      ">>> FINAL ANSWER: Unfortunately, we cannot source 50 GPU-X100s from Taiwan.\n",
      "\n",
      "**Risks identified:**\n",
      "*   **No Stock:** Our inventory shows 0 units available in Taiwan.\n",
      "*   **External Factors:** There is an urgent Super Typhoon 'Kuna' hitting Taiwan, which has resulted in port closures. This would prevent any shipments even if stock were available.\n",
      "\n",
      "**Alternative Sourcing Options with Stock:**\n",
      "*   **Germany:** We have 50 units in stock.\n",
      "*   **India:** We have 50 units in stock.\n",
      "\n",
      "Would you like to proceed with sourcing the 50 GPU-X100s from either Germany or India?\n",
      "\n",
      "[Node: ERP Guard] querying database...\n",
      "\n",
      "⏸ GRAPH PAUSED — HUMAN INPUT REQUIRED\n",
      "Proposed alternative locations: ['germany', 'india']\n"
     ]
    }
   ],
   "source": [
    "# 5. GRAPH BUILD\n",
    "workflow = StateGraph(SupplyChainState)\n",
    "workflow.add_node(\"erp_guard\", erp_lookup_node)\n",
    "workflow.add_node(\"agent\", agent_node)\n",
    "workflow.add_node(\"tools\", ToolNode(tools=tools))\n",
    "workflow.add_node(\"approval\", approval_node)\n",
    "\n",
    "workflow.set_entry_point(\"erp_guard\")\n",
    "workflow.add_edge(\"erp_guard\", \"agent\")\n",
    "\n",
    "def router(state):\n",
    "    last_msg = state[\"messages\"][-1]\n",
    "\n",
    "    if last_msg.tool_calls:\n",
    "        return \"tools\"\n",
    "\n",
    "    if state.get(\"pending_decision\"):\n",
    "        return \"approval\"\n",
    "\n",
    "    return \"end\"\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"agent\",\n",
    "    router,\n",
    "    {\n",
    "        \"tools\": \"tools\",\n",
    "        \"approval\": \"approval\",\n",
    "        \"end\": END\n",
    "    }\n",
    ")\n",
    "\n",
    "workflow.add_edge(\"tools\", \"agent\")\n",
    "workflow.add_edge(\"approval\", END)\n",
    "\n",
    "app = workflow.compile()\n",
    "\n",
    "# 6. RUN\n",
    "print(\"--- SCENARIO: Sourcing from Taiwan (Risky) ---\")\n",
    "inputs = {\n",
    "    \"product_query\": \"GPU\",\n",
    "    \"messages\": [\n",
    "        HumanMessage(content=\"Can we source 50 GPU-X100s from Taiwan??\")\n",
    "    ],\n",
    "    \"last_product\": \"\",\n",
    "    \"last_location\": \"\",\n",
    "    \"alternatives\": [],\n",
    "    \"pending_decision\": None,\n",
    "    \"awaiting_human\": False,\n",
    "    \"decision_log\": []\n",
    "}\n",
    "for output in app.stream(inputs):\n",
    "    pass\n",
    "\n",
    "print(f\"\\n>>> FINAL ANSWER: {app.invoke(inputs)['messages'][-1].content[0]['text']}\")\n",
    "result = app.invoke(inputs)\n",
    "if result.get(\"awaiting_human\"):\n",
    "    print(\"\\n⏸ GRAPH PAUSED — HUMAN INPUT REQUIRED\")\n",
    "\n",
    "    decision = result[\"pending_decision\"]\n",
    "    options = [opt.lower() for opt in decision[\"options\"]]\n",
    "\n",
    "    print(\"Proposed alternative locations:\", options)\n",
    "\n",
    "    choice = input(\n",
    "        f\"Approve shipment from one of {options}? \"\n",
    "        \"(type country name / yes / no): \"\n",
    "    ).strip().lower()\n",
    "\n",
    "    approved_location = None\n",
    "\n",
    "    # ✅ SAFE approval logic\n",
    "    if choice == \"yes\":\n",
    "        approved_location = options[0]\n",
    "    elif choice in options:\n",
    "        approved_location = choice\n",
    "\n",
    "    # ---- LOG DECISION ----\n",
    "    result[\"decision_log\"].append({\n",
    "        \"decision\": decision,\n",
    "        \"approved\": approved_location is not None,\n",
    "        \"chosen_location\": approved_location\n",
    "    })\n",
    "\n",
    "    if approved_location:\n",
    "        result[\"messages\"].append(\n",
    "            SystemMessage(\n",
    "                content=f\"Human approved shipment from {approved_location.title()}.\"\n",
    "            )\n",
    "        )\n",
    "\n",
    "        result[\"pending_decision\"] = None\n",
    "        result[\"awaiting_human\"] = False\n",
    "\n",
    "        # ▶ Resume graph\n",
    "        \n",
    "        print(f\"Human approved shipment from {approved_location.title()}.\")\n",
    "\n",
    "    else:\n",
    "        result[\"messages\"].append(\n",
    "            SystemMessage(content=\"Human rejected shipment. Order cancelled.\")\n",
    "        )\n",
    "\n",
    "        result[\"pending_decision\"] = None\n",
    "        result[\"awaiting_human\"] = False\n",
    "\n",
    "        # ⛔ End workflow\n",
    "        print(\"Human rejected shipment. Order cancelled.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ff2ef3-3e5a-4b0c-93ca-7dfeb7e713b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
