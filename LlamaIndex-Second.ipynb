{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e05a7e0a-22c5-4e71-9a47-278bb851ac1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade llama-index        # core\n",
    "%pip install --upgrade llama-index-llms-google-genai  # Google / Gemini LLM integration\n",
    "%pip install --upgrade llama-index-embeddings-google-genai  # embeddings via Google GenAI\n",
    "%pip install --upgrade google-generativeai  # underlying Google SDK\n",
    "%pip install --upgrade pinecone-client      # if using Pinecone\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41316ccd-c5b7-4707-ac54-83b6d5729c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pinecone import Pinecone\n",
    "from llama_index.vector_stores.pinecone import PineconeVectorStore\n",
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader,Settings, get_response_synthesizer\n",
    "from llama_index.llms.google_genai import GoogleGenAI\n",
    "from llama_index.embeddings.google_genai import GoogleGenAIEmbedding\n",
    "from llama_index.core.retrievers import QueryFusionRetriever\n",
    "from llama_index.core.query_engine import RetrieverQueryEngine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7999c54c-fad2-4787-b0aa-7877ddc1a117",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Force Google models globally BEFORE anything else (prevents OpenAI\n",
    "os.environ.pop(\"OPENAI_API_KEY\", None) # ensure no accidental\n",
    "\n",
    "Settings.embed_model = GoogleGenAIEmbedding(model_name=\"models/text-embedding-004\",api_key=\"\")\n",
    "Settings.llm = GoogleGenAI(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    api_key=\"\",\n",
    "    use_async=True  \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbfd46e2-abdd-491d-a06a-fd2ba0a99b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================\n",
    "# Data layer existing index with 004 emebeding model\n",
    "# =============================================\n",
    "\n",
    "INDEX_NAME = \"coffeeindex\"\n",
    "pc = Pinecone(api_key=\"\")\n",
    "pc_index = pc.Index(INDEX_NAME)\n",
    "vstore = PineconeVectorStore(pinecone_index=pc_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f3058ec-e96d-4f8d-9e60-bcc3a3f30c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858aabb3-5bab-4a91-9036-a2ba7118e52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local PDFs (NO Pinecone upsert; kept in-memory)\n",
    "docs = SimpleDirectoryReader(\"./GenAI/GenAI-NoteBooks/coffee_pages\").load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ba1e91-0ecc-4dfd-850a-56a4d5aa3e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build indexes (use Settings.embed_model)\n",
    "vector_idx = VectorStoreIndex.from_vector_store(vstore) #Pinecone-backed\n",
    "local_idx = VectorStoreIndex.from_documents(docs) #in-memory for PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c123fe82-5ba9-46be-b537-306b5573632f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================ Query layer\n",
    "#============================ (Optional for now)\n",
    "# Auto-fuse Pinecone + PDFs; no query expansion (no hidden LLM calls in retrieval)\n",
    "pinecone_ret = vector_idx.as_retriever(similarity_top_k=5)\n",
    "pdf_ret = local_idx.as_retriever(similarity_top_k=5)\n",
    "hybrid = QueryFusionRetriever(\n",
    " retrievers=[pinecone_ret, pdf_ret],\n",
    " similarity_top_k=5,\n",
    " mode=\"reciprocal_rerank\",\n",
    " num_queries=1,\n",
    " use_async=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0124b587-f3c8-46b6-9fdf-a213cc0cf876",
   "metadata": {},
   "outputs": [],
   "source": [
    "qe = RetrieverQueryEngine.from_args(\n",
    " retriever=hybrid,\n",
    " response_synthesizer=get_response_synthesizer(llm=Settings.llm,\n",
    "response_mode=\"compact\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e4c682-df2f-495c-ad6d-78226a3a49f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe77bfb-f247-436b-95c0-ef4347ca1e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(qe.query(\"Using both PDFs and the vector KB, explain desi brewing in 3 bullets.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68a872c-389d-478e-9385-a39ced1f8d11",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
